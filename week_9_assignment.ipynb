{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecbc8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"itv023333\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.ui.port\", \"0\") \\\n",
    "    .config('spark.shuffle.useOldFetchProtocol', 'true') \\\n",
    "    .config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dc8485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g01.itversity.com:39927\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>itv023333</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ffa90991400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a8939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", LongType()),\n",
    "    StructField(\"user_first_name\", StringType()),\n",
    "    StructField(\"user_last_name\", StringType()),\n",
    "    StructField(\"user_email\", StringType()),\n",
    "    StructField(\"user_gender\", StringType()),\n",
    "    StructField(\"user_phone_numbers\", ArrayType(StringType())),\n",
    "    StructField(\"user_address\",\n",
    "        StructType([\n",
    "        StructField(\"street\", StringType()),\n",
    "        StructField(\"city\", StringType()),\n",
    "        StructField(\"state\", StringType()),\n",
    "        StructField(\"postal_code\", StringType())\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b660d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = spark.read \\\n",
    ".format(\"json\") \\\n",
    ".schema(schema) \\\n",
    ".load(\"/public/sms/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9e3c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- user_first_name: string (nullable = true)\n",
      " |-- user_last_name: string (nullable = true)\n",
      " |-- user_email: string (nullable = true)\n",
      " |-- user_gender: string (nullable = true)\n",
      " |-- user_phone_numbers: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- user_address: struct (nullable = true)\n",
      " |    |-- street: string (nullable = true)\n",
      " |    |-- city: string (nullable = true)\n",
      " |    |-- state: string (nullable = true)\n",
      " |    |-- postal_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7566cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "base_df.withColumn(\"street\",col(\"user_address.street\")) \\\n",
    ".withColumn(\"city\",col(\"user_address.city\")) \\\n",
    ".withColumn(\"state\",col(\"user_address.state\")) \\\n",
    ".withColumn(\"postal_code\",col(\"user_address.postal_code\")) \\\n",
    ".withColumn(\"user_phone_numbers\", size(col(\"user_phone_numbers\"))).createOrReplaceTempView(\"users_vw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164d35cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade3806",
   "metadata": {},
   "source": [
    "a. total number of records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ad89962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4874320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>user_id</th><th>user_first_name</th><th>user_last_name</th><th>user_email</th><th>user_gender</th><th>user_phone_numbers</th><th>user_address</th><th>street</th><th>city</th><th>state</th><th>postal_code</th></tr>\n",
       "<tr><td>700001</td><td>North</td><td>Broxholme</td><td>nbroxholme0@apach...</td><td>Male</td><td>3</td><td>{81 Riverside Par...</td><td>81 Riverside Parkway</td><td>Newark</td><td>New Jersey</td><td>07188</td></tr>\n",
       "<tr><td>700002</td><td>Allan</td><td>Burree</td><td>aburree1@gov.uk</td><td>Male</td><td>3</td><td>{109 Marquette St...</td><td>109 Marquette Street</td><td>Tampa</td><td>Florida</td><td>33625</td></tr>\n",
       "<tr><td>700003</td><td>Marga</td><td>Hertwell</td><td>mhertwell2@flavor...</td><td>Female</td><td>4</td><td>{79158 Acker Way,...</td><td>79158 Acker Way</td><td>Albuquerque</td><td>New Mexico</td><td>87105</td></tr>\n",
       "<tr><td>700004</td><td>Fran</td><td>Snalum</td><td>fsnalum3@tuttocit...</td><td>Female</td><td>5</td><td>{0 Lillian Parkwa...</td><td>0 Lillian Parkway</td><td>Scranton</td><td>Pennsylvania</td><td>18514</td></tr>\n",
       "<tr><td>700005</td><td>Tarrah</td><td>Asty</td><td>tasty4@netlog.com</td><td>Female</td><td>2</td><td>{60 Butternut Par...</td><td>60 Butternut Park</td><td>San Antonio</td><td>Texas</td><td>78245</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+---------------+--------------+--------------------+-----------+------------------+--------------------+--------------------+-----------+------------+-----------+\n",
       "|user_id|user_first_name|user_last_name|          user_email|user_gender|user_phone_numbers|        user_address|              street|       city|       state|postal_code|\n",
       "+-------+---------------+--------------+--------------------+-----------+------------------+--------------------+--------------------+-----------+------------+-----------+\n",
       "| 700001|          North|     Broxholme|nbroxholme0@apach...|       Male|                 3|{81 Riverside Par...|81 Riverside Parkway|     Newark|  New Jersey|      07188|\n",
       "| 700002|          Allan|        Burree|     aburree1@gov.uk|       Male|                 3|{109 Marquette St...|109 Marquette Street|      Tampa|     Florida|      33625|\n",
       "| 700003|          Marga|      Hertwell|mhertwell2@flavor...|     Female|                 4|{79158 Acker Way,...|     79158 Acker Way|Albuquerque|  New Mexico|      87105|\n",
       "| 700004|           Fran|        Snalum|fsnalum3@tuttocit...|     Female|                 5|{0 Lillian Parkwa...|   0 Lillian Parkway|   Scranton|Pennsylvania|      18514|\n",
       "| 700005|         Tarrah|          Asty|   tasty4@netlog.com|     Female|                 2|{60 Butternut Par...|   60 Butternut Park|San Antonio|       Texas|      78245|\n",
       "+-------+---------------+--------------+--------------------+-----------+------------------+--------------------+--------------------+-----------+------------+-----------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from users_vw limit 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3719684",
   "metadata": {},
   "source": [
    "b. how many users are from the state New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488dc390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>distinct_users</th></tr>\n",
       "<tr><td>49576</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------+\n",
       "|distinct_users|\n",
       "+--------------+\n",
       "|         49576|\n",
       "+--------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct user_id) as distinct_users from users_vw where state = 'New York' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be2cb052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>user_id</th><th>user_first_name</th><th>user_last_name</th><th>user_email</th><th>user_gender</th><th>user_phone_numbers</th><th>user_address</th><th>street</th><th>city</th><th>state</th><th>postal_code</th></tr>\n",
       "<tr><td>200001</td><td>Eirena</td><td>Cutsforth</td><td>ecutsforth0@wisc.edu</td><td>Female</td><td>4</td><td>{8 Warrior Drive,...</td><td>8 Warrior Drive</td><td>Dallas</td><td>Texas</td><td>75358</td></tr>\n",
       "<tr><td>200027</td><td>Amalee</td><td>Cicculini</td><td>acicculiniq@frien...</td><td>Female</td><td>2</td><td>{59564 Weeping Bi...</td><td>59564 Weeping Bir...</td><td>Dallas</td><td>Texas</td><td>75372</td></tr>\n",
       "<tr><td>200032</td><td>Bancroft</td><td>O&#x27;Mullally</td><td>bomullallyv@tiny.cc</td><td>Male</td><td>4</td><td>{1087 Quincy Cour...</td><td>1087 Quincy Court</td><td>Dallas</td><td>Texas</td><td>75205</td></tr>\n",
       "<tr><td>200125</td><td>Denver</td><td>De Bruijne</td><td>ddebruijne3g@yaho...</td><td>Male</td><td>3</td><td>{1201 Acker Terra...</td><td>1201 Acker Terrace</td><td>Dallas</td><td>Texas</td><td>75251</td></tr>\n",
       "<tr><td>200127</td><td>Tab</td><td>Lancastle</td><td>tlancastle3i@com.com</td><td>Male</td><td>2</td><td>{20 Elka Road, Da...</td><td>20 Elka Road</td><td>Dallas</td><td>Texas</td><td>75310</td></tr>\n",
       "<tr><td>200142</td><td>Candi</td><td>Glencrash</td><td>cglencrash3x@thea...</td><td>Female</td><td>1</td><td>{15 Burning Wood ...</td><td>15 Burning Wood S...</td><td>Dallas</td><td>Texas</td><td>75387</td></tr>\n",
       "<tr><td>200151</td><td>Meriel</td><td>Doll</td><td>mdoll46@hud.gov</td><td>Female</td><td>4</td><td>{834 Redwing Cour...</td><td>834 Redwing Court</td><td>Dallas</td><td>Texas</td><td>75210</td></tr>\n",
       "<tr><td>200160</td><td>Timmy</td><td>Georgot</td><td>tgeorgot4f@latime...</td><td>Female</td><td>1</td><td>{602 Summit Court...</td><td>602 Summit Court</td><td>Dallas</td><td>Texas</td><td>75260</td></tr>\n",
       "<tr><td>200182</td><td>Sayre</td><td>Larimer</td><td>slarimer51@vkonta...</td><td>Male</td><td>3</td><td>{5 Loeprich Pass,...</td><td>5 Loeprich Pass</td><td>Dallas</td><td>Texas</td><td>75358</td></tr>\n",
       "<tr><td>200290</td><td>Alyosha</td><td>Cudbertson</td><td>acudbertson81@for...</td><td>Male</td><td>1</td><td>{6168 Summerview ...</td><td>6168 Summerview Park</td><td>Dallas</td><td>Texas</td><td>75397</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+---------------+--------------+--------------------+-----------+------------------+--------------------+--------------------+------+-----+-----------+\n",
       "|user_id|user_first_name|user_last_name|          user_email|user_gender|user_phone_numbers|        user_address|              street|  city|state|postal_code|\n",
       "+-------+---------------+--------------+--------------------+-----------+------------------+--------------------+--------------------+------+-----+-----------+\n",
       "| 500124|         Norman|         Elsay|nelsay3f@cocolog-...|       Male|                 1|{32091 Cottonwood...|32091 Cottonwood ...|Dallas|Texas|      75287|\n",
       "| 500128|          Bella|   Winterscale|bwinterscale3j@re...|     Female|                 5|{6 Hauk Crossing,...|     6 Hauk Crossing|Dallas|Texas|      75205|\n",
       "| 500215|         Rustin|        Efford|   refford5y@mit.edu|       Male|                 2|{8028 Straubel Wa...|   8028 Straubel Way|Dallas|Texas|      75226|\n",
       "| 500315|           Paco|       Gergher|  pgergher8q@ted.com|       Male|                 4|{46 Pawling Cente...|   46 Pawling Center|Dallas|Texas|      75241|\n",
       "| 500686|      Chevalier|      Donnelly|cdonnellyj1@googl...|       Male|                 1|{94 Daystar Drive...|    94 Daystar Drive|Dallas|Texas|      75310|\n",
       "| 500744|            Cad|      Lochhead|clochheadkn@blogs...|       Male|                 4|{3 Ridgeview Circ...|  3 Ridgeview Circle|Dallas|Texas|      75236|\n",
       "| 500917|           Toby|     Corbridge|tcorbridgepg@blog...|       Male|                 4|{1 Sycamore Junct...| 1 Sycamore Junction|Dallas|Texas|      75367|\n",
       "| 500992|          Erwin|     Shilliday|eshillidayrj@seat...|       Male|                 5|{247 Bobwhite All...|  247 Bobwhite Alley|Dallas|Texas|      75251|\n",
       "| 501143|        Andreas|        Cherry|    acherryvq@w3.org|       Male|                 4|{04143 Corry Junc...|04143 Corry Junction|Dallas|Texas|      75251|\n",
       "| 501382|      Sigismund|      Wilstead|swilstead12d@walm...|       Male|                 5|{0 Amoth Pass, Da...|        0 Amoth Pass|Dallas|Texas|      75246|\n",
       "+-------+---------------+--------------+--------------------+-----------+------------------+--------------------+--------------------+------+-----+-----------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from users_vw where city = 'Dallas' LIMIT 10 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022ccc4",
   "metadata": {},
   "source": [
    "c. which state has maximum number of postal codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfa6f0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>max_postcode</th><th>state</th></tr>\n",
       "<tr><td>206</td><td>California</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+----------+\n",
       "|max_postcode|     state|\n",
       "+------------+----------+\n",
       "|         206|California|\n",
       "+------------+----------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct postal_code) as max_postcode, state from users_vw group by state order by max_postcode desc limit 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f90386",
   "metadata": {},
   "source": [
    "d. which city has the most number of users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34bbc1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>city</th><th>no_distinct_users</th></tr>\n",
       "<tr><td>Washington</td><td>28504</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+-----------------+\n",
       "|      city|no_distinct_users|\n",
       "+----------+-----------------+\n",
       "|Washington|            28504|\n",
       "+----------+-----------------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select city, count(distinct user_id) as no_distinct_users from users_vw where city is not null group by city order by no_distinct_users desc limit 1  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3f5b5",
   "metadata": {},
   "source": [
    "e. how many users have email domain as bizjournals.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e4bb1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>users</th></tr>\n",
       "<tr><td>2015</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+\n",
       "|users|\n",
       "+-----+\n",
       "| 2015|\n",
       "+-----+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select count(user_id) as users from users_vw where user_email like '%bizjournals.com'\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dac47c",
   "metadata": {},
   "source": [
    "f. how many users have 4 phone numbers mentioned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67b33cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>no_of_users</th></tr>\n",
       "<tr><td>179041</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+\n",
       "|no_of_users|\n",
       "+-----------+\n",
       "|     179041|\n",
       "+-----------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select count(distinct user_id) no_of_users from users_vw where user_phone_numbers ='4'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf56cbb",
   "metadata": {},
   "source": [
    "g. how many users do not have any phone number mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6288f355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>no_of_users</th></tr>\n",
       "<tr><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+\n",
       "|no_of_users|\n",
       "+-----------+\n",
       "|          0|\n",
       "+-----------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select count(distinct user_id ) as no_of_users \n",
    "from users_vw \n",
    "where user_phone_numbers is null\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc361e",
   "metadata": {},
   "source": [
    "Question 3 \\\n",
    "Write the data from the base dataframe as it is to the disk, but write in parquet\n",
    "format. \\\n",
    "Observe the number of files created, also the size of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0deacefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.write \\\n",
    ".option(\"path\",\"/user/itv023333/week9/assignment\") \\\n",
    ".mode(\"overwrite\") \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b085845",
   "metadata": {},
   "source": [
    "Question 5 \\\n",
    "Create a pivot where states should be the rows and user_gender should be\n",
    "the columns. \\\n",
    "Something like below, the aggregation is based on the number of records\n",
    "under each category where the phone number is not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a0d12f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>state</th><th>Male</th><th>Female</th></tr>\n",
       "<tr><td>Alabama</td><td>9307</td><td>9178</td></tr>\n",
       "<tr><td>Alaska</td><td>1882</td><td>1938</td></tr>\n",
       "<tr><td>Arizona</td><td>9406</td><td>9543</td></tr>\n",
       "<tr><td>Arkansas</td><td>2420</td><td>2416</td></tr>\n",
       "<tr><td>California</td><td>49120</td><td>48716</td></tr>\n",
       "<tr><td>Colorado</td><td>10128</td><td>10125</td></tr>\n",
       "<tr><td>Connecticut</td><td>5797</td><td>5917</td></tr>\n",
       "<tr><td>Delaware</td><td>1651</td><td>1654</td></tr>\n",
       "<tr><td>District of Columbia</td><td>14212</td><td>14292</td></tr>\n",
       "<tr><td>Florida</td><td>36692</td><td>36688</td></tr>\n",
       "<tr><td>Georgia</td><td>13008</td><td>13028</td></tr>\n",
       "<tr><td>Hawaii</td><td>2172</td><td>2062</td></tr>\n",
       "<tr><td>Idaho</td><td>2058</td><td>2101</td></tr>\n",
       "<tr><td>Illinois</td><td>11178</td><td>11267</td></tr>\n",
       "<tr><td>Indiana</td><td>9604</td><td>9676</td></tr>\n",
       "<tr><td>Iowa</td><td>4706</td><td>4726</td></tr>\n",
       "<tr><td>Kansas</td><td>5962</td><td>5776</td></tr>\n",
       "<tr><td>Kentucky</td><td>6216</td><td>6108</td></tr>\n",
       "<tr><td>Louisiana</td><td>8706</td><td>8631</td></tr>\n",
       "<tr><td>Maine</td><td>225</td><td>228</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+-----+------+\n",
       "|               state| Male|Female|\n",
       "+--------------------+-----+------+\n",
       "|             Alabama| 9307|  9178|\n",
       "|              Alaska| 1882|  1938|\n",
       "|             Arizona| 9406|  9543|\n",
       "|            Arkansas| 2420|  2416|\n",
       "|          California|49120| 48716|\n",
       "|            Colorado|10128| 10125|\n",
       "|         Connecticut| 5797|  5917|\n",
       "|            Delaware| 1651|  1654|\n",
       "|District of Columbia|14212| 14292|\n",
       "|             Florida|36692| 36688|\n",
       "|             Georgia|13008| 13028|\n",
       "|              Hawaii| 2172|  2062|\n",
       "|               Idaho| 2058|  2101|\n",
       "|            Illinois|11178| 11267|\n",
       "|             Indiana| 9604|  9676|\n",
       "|                Iowa| 4706|  4726|\n",
       "|              Kansas| 5962|  5776|\n",
       "|            Kentucky| 6216|  6108|\n",
       "|           Louisiana| 8706|  8631|\n",
       "|               Maine|  225|   228|\n",
       "+--------------------+-----+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"select state,\n",
    "sum(Male_cnt) as Male,\n",
    "sum(Female_cnt) as Female\n",
    "from\n",
    "(select state,\n",
    "case when user_gender='Male' then count(user_id) end as Male_cnt,\n",
    "case when user_gender='Female' then count(user_id) end as\n",
    "Female_cnt\n",
    "from users_vw\n",
    "where state is not null and user_phone_numbers is not null\n",
    "group by state,user_gender)\n",
    "group by state\n",
    "order by state\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d0215d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".load(\"/public/airlines_all/airlines/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2c8a701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1919"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873e34a",
   "metadata": {},
   "source": [
    "If we add below configuration to spark session \\\n",
    "it will increase the block size from 128 mb to 140 mb \\\n",
    "if we combine two files it will be more than 128 mb so mergining files is not happing here \\ \n",
    "thats why we are getting 1919 partitions cuz that many files are present \\\n",
    "but with below configuration block size will be 140 mb and spark can merge 2 files \\\n",
    "and number of block size will be increased so partitions will be reduced to half "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f999cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"itv023333\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.ui.port\", \"0\") \\\n",
    "    .config('spark.shuffle.useOldFetchProtocol', 'true') \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"146800640\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d20572",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".load(\"/public/airlines_all/airlines/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4291d554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4072ad06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
