{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a67c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"cache_pyspark2\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.ui.port\", \"0\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42398f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g01.itversity.com:45695\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>cache_pyspark2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdca3831ac8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a26bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_schema = \"customer_id long, purchase_date date, product_id long, amount double\"\n",
    "cust_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".schema(cust_schema) \\\n",
    ".load(\"/public/trendytech/datasets/cust_transf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "430db8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2023-05-01\"\n",
    "end_date = \"2023-06-08\"\n",
    "filtered_df = cust_df.filter((cust_df.purchase_date >= start_date) & (cust_df.purchase_date <= end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e8a6cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|product_id|              amount|\n",
      "+----------+--------------------+\n",
      "|      1003| 5.725592243903786E8|\n",
      "|      1001|  5.56682641192824E8|\n",
      "|      1002|4.2938362439486486E8|\n",
      "|      1004| 2.862080244027619E8|\n",
      "|      1005| 2.782856412021384E8|\n",
      "|      1015|  12537.909999999963|\n",
      "|      1014|  11492.909999999963|\n",
      "|      1013|  10447.909999999963|\n",
      "|      1012|   9402.909999999965|\n",
      "|      1011|   8357.909999999967|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_product = filtered_df.groupBy('product_id').sum('amount').withColumnRenamed(\"sum(amount)\", 'amount')\n",
    "top_products_no_cache  = top_product.sort(\"amount\", ascending = False).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553672df",
   "metadata": {},
   "source": [
    "with cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2273938",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cached_df = cust_df.filter((cust_df.purchase_date >= start_date) & (cust_df.purchase_date <= end_date)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a954a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|product_id|              amount|\n",
      "+----------+--------------------+\n",
      "|      1003| 5.725592243903786E8|\n",
      "|      1001| 5.566826411928239E8|\n",
      "|      1002| 4.293836243948648E8|\n",
      "|      1004|2.8620802440276194E8|\n",
      "|      1005| 2.782856412021384E8|\n",
      "|      1015|  12537.909999999963|\n",
      "|      1014|  11492.909999999963|\n",
      "|      1013|  10447.909999999963|\n",
      "|      1012|   9402.909999999965|\n",
      "|      1011|   8357.909999999967|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_product_cache = filtered_cached_df.groupBy('product_id').sum('amount').withColumnRenamed(\"sum(amount)\", 'amount')\n",
    "top_products_no_cache  = top_product_cache.sort(\"amount\", ascending = False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3020420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|product_id|              amount|\n",
      "+----------+--------------------+\n",
      "|      1003| 5.725592243903786E8|\n",
      "|      1001|  5.56682641192824E8|\n",
      "|      1002| 4.293836243948648E8|\n",
      "|      1004|2.8620802440276194E8|\n",
      "|      1005| 2.782856412021384E8|\n",
      "|      1015|  12537.909999999963|\n",
      "|      1014|  11492.909999999963|\n",
      "|      1013|  10447.909999999963|\n",
      "|      1012|   9402.909999999965|\n",
      "|      1011|   8357.909999999967|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_products_no_cache  = top_product_cache.sort(\"amount\", ascending = False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e48b135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------+\n",
      "|customer_id|purchase_date|product_id|amount|\n",
      "+-----------+-------------+----------+------+\n",
      "|       1001|   2023-05-15|      1001| 49.99|\n",
      "|       1002|   2023-05-16|      1002| 29.99|\n",
      "|       1003|   2023-05-17|      1003| 39.99|\n",
      "|       1004|   2023-05-18|      1004| 19.99|\n",
      "|       1005|   2023-05-19|      1005| 24.99|\n",
      "+-----------+-------------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e42a006",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'groupBY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-14eafa45d3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_cust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sum(amount)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'transactio_amt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtop_cust_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_cust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1305\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1306\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'groupBY'"
     ]
    }
   ],
   "source": [
    "top_cust = filtered_df.groupBY('customer_id').sum('amount').withColumnRenamed(\"sum(amount)\",'transactio_amt')\n",
    "top_cust_df = top_cust.sort('customer_id',ascending=False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4de32822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table itv023333.customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d853775f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop database itv023333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f3cc846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database itv023333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd39dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df.write.format(\"csv\").saveAsTable(\"itv023333.customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5080b7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>purchase_date</th><th>product_id</th><th>amount</th></tr>\n",
       "<tr><td>1012</td><td>2023-06-12</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1013</td><td>2023-06-13</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1014</td><td>2023-06-14</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1015</td><td>2023-06-15</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-15</td><td>1001</td><td>49.99</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-------------+----------+------+\n",
       "|customer_id|purchase_date|product_id|amount|\n",
       "+-----------+-------------+----------+------+\n",
       "|       1003|   2023-06-01|      1005| 24.99|\n",
       "|       1004|   2023-06-02|      1001| 49.99|\n",
       "|       1005|   2023-06-03|      1002| 29.99|\n",
       "|       1001|   2023-06-04|      1003| 39.99|\n",
       "|       1002|   2023-06-05|      1004| 19.99|\n",
       "+-----------+-------------+----------+------+"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from itv023333.customers limit 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abbbe5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product_id</th><th>amount</th></tr>\n",
       "<tr><td>1003</td><td>5.725592243903785E8</td></tr>\n",
       "<tr><td>1001</td><td>5.566826411928239E8</td></tr>\n",
       "<tr><td>1002</td><td>4.293836243948648E8</td></tr>\n",
       "<tr><td>1004</td><td>2.8620802440276194E8</td></tr>\n",
       "<tr><td>1005</td><td>2.782856412021384E8</td></tr>\n",
       "<tr><td>1015</td><td>12537.909999999963</td></tr>\n",
       "<tr><td>1014</td><td>11492.909999999963</td></tr>\n",
       "<tr><td>1013</td><td>10447.909999999963</td></tr>\n",
       "<tr><td>1012</td><td>9402.909999999965</td></tr>\n",
       "<tr><td>1011</td><td>8357.909999999967</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------------------+\n",
       "|product_id|              amount|\n",
       "+----------+--------------------+\n",
       "|      1003| 5.725592243903785E8|\n",
       "|      1001| 5.566826411928239E8|\n",
       "|      1002| 4.293836243948648E8|\n",
       "|      1004|2.8620802440276194E8|\n",
       "|      1005| 2.782856412021384E8|\n",
       "|      1015|  12537.909999999963|\n",
       "|      1014|  11492.909999999963|\n",
       "|      1013|  10447.909999999963|\n",
       "|      1012|   9402.909999999965|\n",
       "|      1011|   8357.909999999967|\n",
       "+----------+--------------------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select product_id, sum(amount) as amount from itv023333.customers where purchase_date between '2023-05-01' and '2023-06-08' group by product_id order by amount desc limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25c3625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>amount</th></tr>\n",
       "<tr><td>1001</td><td>3.180884580005336E8</td></tr>\n",
       "<tr><td>1004</td><td>3.101342580008686E8</td></tr>\n",
       "<tr><td>1005</td><td>2.624090580015123E8</td></tr>\n",
       "<tr><td>1003</td><td>2.1468385800145328E8</td></tr>\n",
       "<tr><td>1002</td><td>2.0672965800144076E8</td></tr>\n",
       "<tr><td>1011</td><td>1.2724374111049214E8</td></tr>\n",
       "<tr><td>1006</td><td>1.2723851611049211E8</td></tr>\n",
       "<tr><td>1012</td><td>1.1133638611046082E8</td></tr>\n",
       "<tr><td>1007</td><td>1.1133116111046082E8</td></tr>\n",
       "<tr><td>1013</td><td>9.542903111041903E7</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+--------------------+\n",
       "|customer_id|              amount|\n",
       "+-----------+--------------------+\n",
       "|       1001|3.1808845800053364E8|\n",
       "|       1004| 3.101342580008687E8|\n",
       "|       1005|2.6240905800151226E8|\n",
       "|       1003|2.1468385800145325E8|\n",
       "|       1002|2.0672965800144076E8|\n",
       "|       1011|1.2724374111049213E8|\n",
       "|       1006|1.2723851611049213E8|\n",
       "|       1012|1.1133638611046082E8|\n",
       "|       1007|1.1133116111046082E8|\n",
       "|       1013| 9.542903111041903E7|\n",
       "+-----------+--------------------+"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select customer_id, sum(amount) as amount from itv023333.customers where purchase_date between '2023-05-01' and '2023-06-08' group by customer_id order by amount desc limit 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf3d1a",
   "metadata": {},
   "source": [
    "after caching table itv023333.customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9de858e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"cache table itv023333.customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "293fcb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product_id</th><th>amount</th></tr>\n",
       "<tr><td>1003</td><td>5.725592243903786E8</td></tr>\n",
       "<tr><td>1001</td><td>5.566826411928239E8</td></tr>\n",
       "<tr><td>1002</td><td>4.2938362439486486E8</td></tr>\n",
       "<tr><td>1004</td><td>2.8620802440276194E8</td></tr>\n",
       "<tr><td>1005</td><td>2.782856412021384E8</td></tr>\n",
       "<tr><td>1015</td><td>12537.909999999963</td></tr>\n",
       "<tr><td>1014</td><td>11492.909999999963</td></tr>\n",
       "<tr><td>1013</td><td>10447.909999999963</td></tr>\n",
       "<tr><td>1012</td><td>9402.909999999965</td></tr>\n",
       "<tr><td>1011</td><td>8357.909999999967</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------------------+\n",
       "|product_id|              amount|\n",
       "+----------+--------------------+\n",
       "|      1003| 5.725592243903786E8|\n",
       "|      1001| 5.566826411928239E8|\n",
       "|      1002| 4.293836243948648E8|\n",
       "|      1004|2.8620802440276194E8|\n",
       "|      1005| 2.782856412021384E8|\n",
       "|      1015|  12537.909999999963|\n",
       "|      1014|  11492.909999999963|\n",
       "|      1013|  10447.909999999963|\n",
       "|      1012|   9402.909999999965|\n",
       "|      1011|   8357.909999999967|\n",
       "+----------+--------------------+"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select product_id, sum(amount) as amount from itv023333.customers where purchase_date between '2023-05-01' and '2023-06-08' group by product_id order by amount desc limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3954ab88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>amount</th></tr>\n",
       "<tr><td>1001</td><td>3.180884580005336E8</td></tr>\n",
       "<tr><td>1004</td><td>3.101342580008687E8</td></tr>\n",
       "<tr><td>1005</td><td>2.624090580015123E8</td></tr>\n",
       "<tr><td>1003</td><td>2.1468385800145325E8</td></tr>\n",
       "<tr><td>1002</td><td>2.0672965800144076E8</td></tr>\n",
       "<tr><td>1011</td><td>1.2724374111049214E8</td></tr>\n",
       "<tr><td>1006</td><td>1.2723851611049213E8</td></tr>\n",
       "<tr><td>1012</td><td>1.113363861104608E8</td></tr>\n",
       "<tr><td>1007</td><td>1.1133116111046082E8</td></tr>\n",
       "<tr><td>1013</td><td>9.542903111041903E7</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+--------------------+\n",
       "|customer_id|              amount|\n",
       "+-----------+--------------------+\n",
       "|       1001| 3.180884580005336E8|\n",
       "|       1004| 3.101342580008687E8|\n",
       "|       1005|2.6240905800151232E8|\n",
       "|       1003|2.1468385800145325E8|\n",
       "|       1002| 2.067296580014408E8|\n",
       "|       1011|1.2724374111049213E8|\n",
       "|       1006|1.2723851611049213E8|\n",
       "|       1012|1.1133638611046082E8|\n",
       "|       1007| 1.113311611104608E8|\n",
       "|       1013| 9.542903111041905E7|\n",
       "+-----------+--------------------+"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select customer_id, sum(amount) as amount from itv023333.customers where purchase_date between '2023-05-01' and '2023-06-08' group by customer_id order by amount desc limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39a20399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------+\n",
      "|customer_id|purchase_date|product_id|amount|\n",
      "+-----------+-------------+----------+------+\n",
      "|       1001|   2023-05-15|      1001| 49.99|\n",
      "|       1002|   2023-05-16|      1002| 29.99|\n",
      "|       1003|   2023-05-17|      1003| 39.99|\n",
      "|       1004|   2023-05-18|      1004| 19.99|\n",
      "|       1005|   2023-05-19|      1005| 24.99|\n",
      "+-----------+-------------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84acfd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|customer_id|purchase_date|\n",
      "+-----------+-------------+\n",
      "|       1008|   2023-05-24|\n",
      "|       1002|   2023-05-26|\n",
      "|       1002|   2023-06-05|\n",
      "|       1013|   2023-06-13|\n",
      "|       1009|   2023-06-14|\n",
      "|       1006|   2023-06-01|\n",
      "|       1011|   2023-06-06|\n",
      "|       1013|   2023-05-29|\n",
      "|       1004|   2023-06-07|\n",
      "|       1007|   2023-06-07|\n",
      "|       1004|   2023-05-18|\n",
      "|       1001|   2023-05-30|\n",
      "|       1002|   2023-05-31|\n",
      "|       1007|   2023-06-12|\n",
      "|       1001|   2023-06-04|\n",
      "|       1009|   2023-06-04|\n",
      "|       1005|   2023-06-08|\n",
      "|       1003|   2023-05-22|\n",
      "|       1012|   2023-06-12|\n",
      "|       1005|   2023-06-03|\n",
      "+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.select('customer_id','purchase_date').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b86f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27badef",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cust_df = cust_df.withColumn(\"purchase_year\",year(\"purchase_date\")).withColumn(\"purchase_month\",month(\"purchase_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12489d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_month_count = new_cust_df.groupBy('customer_id','purchase_date','purchase_month') \\\n",
    ".agg(countDistinct('purchase_month')) \\\n",
    ".alias(\"distinct_months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fecaa90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`distinct_months`' given input columns: [distinct_months.customer_id, distinct_months.purchase_date, distinct_months.purchase_month, distinct_months.count(DISTINCT purchase_month)]; line 1 pos 0;\\n'Filter ('distinct_months = 1)\\n+- SubqueryAlias `distinct_months`\\n   +- Aggregate [customer_id#0L, purchase_date#1, purchase_month#27], [customer_id#0L, purchase_date#1, purchase_month#27, count(distinct purchase_month#27) AS count(DISTINCT purchase_month)#41L]\\n      +- Project [customer_id#0L, purchase_date#1, product_id#2L, amount#3, purchase_year#21, month(purchase_date#1) AS purchase_month#27]\\n         +- Project [customer_id#0L, purchase_date#1, product_id#2L, amount#3, year(purchase_date#1) AS purchase_year#21]\\n            +- Relation[customer_id#0L,purchase_date#1,product_id#2L,amount#3] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o116.filter.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`distinct_months`' given input columns: [distinct_months.customer_id, distinct_months.purchase_date, distinct_months.purchase_month, distinct_months.count(DISTINCT purchase_month)]; line 1 pos 0;\n'Filter ('distinct_months = 1)\n+- SubqueryAlias `distinct_months`\n   +- Aggregate [customer_id#0L, purchase_date#1, purchase_month#27], [customer_id#0L, purchase_date#1, purchase_month#27, count(distinct purchase_month#27) AS count(DISTINCT purchase_month)#41L]\n      +- Project [customer_id#0L, purchase_date#1, product_id#2L, amount#3, purchase_year#21, month(purchase_date#1) AS purchase_month#27]\n         +- Project [customer_id#0L, purchase_date#1, product_id#2L, amount#3, year(purchase_date#1) AS purchase_year#21]\n            +- Relation[customer_id#0L,purchase_date#1,product_id#2L,amount#3] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:176)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:182)\n\tat org.apache.spark.sql.Dataset$.apply(Dataset.scala:64)\n\tat org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3417)\n\tat org.apache.spark.sql.Dataset.filter(Dataset.scala:1490)\n\tat org.apache.spark.sql.Dataset.filter(Dataset.scala:1504)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a423fd700c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregular_customers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcut_month_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distinct_months = 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"customer_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mregular_customers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m   1362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`distinct_months`' given input columns: [distinct_months.customer_id, distinct_months.purchase_date, distinct_months.purchase_month, distinct_months.count(DISTINCT purchase_month)]; line 1 pos 0;\\n'Filter ('distinct_months = 1)\\n+- SubqueryAlias `distinct_months`\\n   +- Aggregate [customer_id#0L, purchase_date#1, purchase_month#27], [customer_id#0L, purchase_date#1, purchase_month#27, count(distinct purchase_month#27) AS count(DISTINCT purchase_month)#41L]\\n      +- Project [customer_id#0L, purchase_date#1, product_id#2L, amount#3, purchase_year#21, month(purchase_date#1) AS purchase_month#27]\\n         +- Project [customer_id#0L, purchase_date#1, product_id#2L, amount#3, year(purchase_date#1) AS purchase_year#21]\\n            +- Relation[customer_id#0L,purchase_date#1,product_id#2L,amount#3] csv\\n\""
     ]
    }
   ],
   "source": [
    "regular_customers = cut_month_count.filter(\"distinct_months = 1\") \\\n",
    ".groupBy(\"customer_id\").count() \\\n",
    ".orderBy(\"count\", ascending=False).limit(10)\n",
    "regular_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456ce293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------+\n",
      "|customer_id|purchase_date|product_id|amount|\n",
      "+-----------+-------------+----------+------+\n",
      "|       1001|   2023-05-15|      1001| 49.99|\n",
      "|       1002|   2023-05-16|      1002| 29.99|\n",
      "|       1003|   2023-05-17|      1003| 39.99|\n",
      "|       1004|   2023-05-18|      1004| 19.99|\n",
      "|       1005|   2023-05-19|      1005| 24.99|\n",
      "|       1001|   2023-05-20|      1002| 29.99|\n",
      "|       1002|   2023-05-21|      1003| 39.99|\n",
      "|       1003|   2023-05-22|      1004| 19.99|\n",
      "|       1004|   2023-05-23|      1005| 24.99|\n",
      "|       1005|   2023-05-24|      1001| 49.99|\n",
      "|       1001|   2023-05-25|      1003| 39.99|\n",
      "|       1002|   2023-05-26|      1004| 19.99|\n",
      "|       1003|   2023-05-27|      1005| 24.99|\n",
      "|       1004|   2023-05-28|      1001| 49.99|\n",
      "|       1005|   2023-05-29|      1002| 29.99|\n",
      "|       1001|   2023-05-30|      1003| 39.99|\n",
      "|       1002|   2023-05-31|      1004| 19.99|\n",
      "|       1003|   2023-06-01|      1005| 24.99|\n",
      "|       1004|   2023-06-02|      1001| 49.99|\n",
      "|       1005|   2023-06-03|      1002| 29.99|\n",
      "+-----------+-------------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ccb403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87498290"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7188c3",
   "metadata": {},
   "source": [
    "persist dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04eeb468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b07b0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_cust_df = cust_df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b21e803b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87498290"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_cust_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bc6f492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87498290"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_cust_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b5b503a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>purchase_date</th><th>product_id</th><th>amount</th></tr>\n",
       "<tr><td>1001</td><td>2023-05-15</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-16</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-17</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-18</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-19</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-20</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-21</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-22</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-23</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-24</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-25</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-26</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-27</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-28</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-29</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-30</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-31</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-06-01</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-06-02</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-06-03</td><td>1002</td><td>29.99</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------+-------------+----------+------+\n",
       "|customer_id|purchase_date|product_id|amount|\n",
       "+-----------+-------------+----------+------+\n",
       "|       1001|   2023-05-15|      1001| 49.99|\n",
       "|       1002|   2023-05-16|      1002| 29.99|\n",
       "|       1003|   2023-05-17|      1003| 39.99|\n",
       "|       1004|   2023-05-18|      1004| 19.99|\n",
       "|       1005|   2023-05-19|      1005| 24.99|\n",
       "|       1001|   2023-05-20|      1002| 29.99|\n",
       "|       1002|   2023-05-21|      1003| 39.99|\n",
       "|       1003|   2023-05-22|      1004| 19.99|\n",
       "|       1004|   2023-05-23|      1005| 24.99|\n",
       "|       1005|   2023-05-24|      1001| 49.99|\n",
       "|       1001|   2023-05-25|      1003| 39.99|\n",
       "|       1002|   2023-05-26|      1004| 19.99|\n",
       "|       1003|   2023-05-27|      1005| 24.99|\n",
       "|       1004|   2023-05-28|      1001| 49.99|\n",
       "|       1005|   2023-05-29|      1002| 29.99|\n",
       "|       1001|   2023-05-30|      1003| 39.99|\n",
       "|       1002|   2023-05-31|      1004| 19.99|\n",
       "|       1003|   2023-06-01|      1005| 24.99|\n",
       "|       1004|   2023-06-02|      1001| 49.99|\n",
       "|       1005|   2023-06-03|      1002| 29.99|\n",
       "+-----------+-------------+----------+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_cust_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce680683",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_cust_df = cust_df.persist(StorageLevel.MEMORY_AND_DISK_SER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46360f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87498290"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_cust_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce722b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>purchase_date</th><th>product_id</th><th>amount</th></tr>\n",
       "<tr><td>1001</td><td>2023-05-15</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-16</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-17</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-18</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-19</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-20</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-21</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-22</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-23</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-24</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-25</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-26</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-27</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-28</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-29</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-30</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-31</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-06-01</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-06-02</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-06-03</td><td>1002</td><td>29.99</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "DataFrame[customer_id: bigint, purchase_date: date, product_id: bigint, amount: double]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_cust_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0246eec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87498290"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_cust_df = cust_df.persist(StorageLevel(True,False,False,False,1))\n",
    "persist_cust_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d1e8724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>purchase_date</th><th>product_id</th><th>amount</th></tr>\n",
       "<tr><td>1001</td><td>2023-05-15</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-16</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-17</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-18</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-19</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-20</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-21</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-22</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-23</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-24</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-25</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-26</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-27</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-28</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-29</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-30</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-31</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-06-01</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-06-02</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-06-03</td><td>1002</td><td>29.99</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "DataFrame[customer_id: bigint, purchase_date: date, product_id: bigint, amount: double]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_cust_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4f76a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87498290"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_cust_df = cust_df.persist(StorageLevel(False,True,False,True,1))\n",
    "persist_cust_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fec35f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>purchase_date</th><th>product_id</th><th>amount</th></tr>\n",
       "<tr><td>1001</td><td>2023-05-15</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-16</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-17</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-18</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-19</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-20</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-21</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-22</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-23</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-24</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-25</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-26</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-05-27</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-05-28</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-05-29</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-30</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1002</td><td>2023-05-31</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1003</td><td>2023-06-01</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1004</td><td>2023-06-02</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-06-03</td><td>1002</td><td>29.99</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "DataFrame[customer_id: bigint, purchase_date: date, product_id: bigint, amount: double]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_cust_df.unpersist() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29f2ee27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"uncache table itv023333.customers\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feb4b962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table itv023333.hotel_df(booking_id int,guest_name string, checkin_date date, checkout_date date, room_type string,total_price double) using CSV location '/public/trendytech/datasets/hotel_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9cddc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>booking_id</th><th>guest_name</th><th>checkin_date</th><th>checkout_date</th><th>room_type</th><th>total_price</th></tr>\n",
       "<tr><td>1</td><td>John Doe</td><td>2023-05-01</td><td>2023-05-05</td><td>Standard</td><td>400.0</td></tr>\n",
       "<tr><td>2</td><td>Jane Smith</td><td>2023-05-02</td><td>2023-05-06</td><td>Deluxe</td><td>600.0</td></tr>\n",
       "<tr><td>3</td><td>Mark Johnson</td><td>2023-05-03</td><td>2023-05-08</td><td>Standard</td><td>450.0</td></tr>\n",
       "<tr><td>4</td><td>Sarah Wilson</td><td>2023-05-04</td><td>2023-05-07</td><td>Executive</td><td>750.0</td></tr>\n",
       "<tr><td>5</td><td>Emily Brown</td><td>2023-05-06</td><td>2023-05-09</td><td>Deluxe</td><td>550.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+------------+------------+-------------+---------+-----------+\n",
       "|booking_id|  guest_name|checkin_date|checkout_date|room_type|total_price|\n",
       "+----------+------------+------------+-------------+---------+-----------+\n",
       "|         1|    John Doe|  2023-05-01|   2023-05-05| Standard|      400.0|\n",
       "|         2|  Jane Smith|  2023-05-02|   2023-05-06|   Deluxe|      600.0|\n",
       "|         3|Mark Johnson|  2023-05-03|   2023-05-08| Standard|      450.0|\n",
       "|         4|Sarah Wilson|  2023-05-04|   2023-05-07|Executive|      750.0|\n",
       "|         5| Emily Brown|  2023-05-06|   2023-05-09|   Deluxe|      550.0|\n",
       "+----------+------------+------------+-------------+---------+-----------+"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from itv023333.hotel_df limit 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edc11f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(booking_id)</th></tr>\n",
       "<tr><td>107</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+\n",
       "|count(booking_id)|\n",
       "+-----------------+\n",
       "|              107|\n",
       "+-----------------+"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(booking_id) from itv023333.hotel_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41d7fd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"cache table itv023333.hotel_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60b0439b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(booking_id)</th></tr>\n",
       "<tr><td>107</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+\n",
       "|count(booking_id)|\n",
       "+-----------------+\n",
       "|              107|\n",
       "+-----------------+"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(booking_id) from itv023333.hotel_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4aa98a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"uncache table itv023333.hotel_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6218b435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "|room_type|        avg_price|\n",
      "+---------+-----------------+\n",
      "|Executive|            750.0|\n",
      "|   Deluxe|575.5813953488372|\n",
      "| Standard|            425.0|\n",
      "+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select room_type,avg(total_price) as avg_price from itv023333.hotel_df group by room_type\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "319fb293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"cache table itv023333.hotel_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9dda7a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "|room_type|        avg_price|\n",
      "+---------+-----------------+\n",
      "|Executive|            750.0|\n",
      "|   Deluxe|575.5813953488372|\n",
      "| Standard|            425.0|\n",
      "+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select room_type,avg(total_price) as avg_price from itv023333.hotel_df group by room_type\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae971076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"uncache table itv023333.hotel_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb57a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
